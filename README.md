# ğŸ§  Social Media Text Moderization

A **BERT-powered social media text moderation system** that automatically detects and filters toxic, offensive, or inappropriate text content.  
This project leverages **Natural Language Processing (NLP)** and **Machine Learning (ML)** models to ensure a safer and more respectful online environment.

---

## ğŸš€ Features

- ğŸ” Detects multiple toxicity categories â€” *toxic, severe toxic, obscene, threat, insult, identity hate, etc.*
- âš™ï¸ Built using **BERT** and **FastAPI**
- ğŸ§¹ Advanced text preprocessing â€” tokenization, lemmatization, stopword removal, emoji handling
- ğŸŒ Interactive web interface built with **HTML + FastAPI templates**
- ğŸ“¦ Easy to deploy locally or on the cloud
- ğŸ§  Supports model training and fine-tuning via Jupyter Notebook

---

## ğŸ§© Project Structure

socialmediatextmoderization/
â”‚
â”œâ”€â”€ Backend/
â”‚ â”œâ”€â”€ main.py # FastAPI app to serve the model
â”‚ â”œâ”€â”€ toxic_bert_model/ # Trained BERT model & tokenizer files
â”‚ â”œâ”€â”€ utils/
â”‚ â”‚ â””â”€â”€ preprocessing.py # Text preprocessing utilities
â”‚ â””â”€â”€ models/
â”‚ â””â”€â”€ text_model.py # Model architecture and inference logic
â”‚
â”œâ”€â”€ frontend/
â”‚ â””â”€â”€ index.html # Web interface for text moderation
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ text/
â”‚ â”œâ”€â”€ combined_dataset.csv # Training dataset
â”‚ â””â”€â”€ other_dataset_files
â”‚
â”œâ”€â”€ text_combine_csv.py # Script to merge multiple datasets
â””â”€â”€ text.ipynb # Jupyter Notebook for model training


---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|------------|-------------|
| **Language** | Python 3.x |
| **Frameworks** | FastAPI, Jinja2 |
| **ML / NLP Libraries** | Transformers (BERT), PyTorch, scikit-learn, spaCy, nltk |
| **Frontend** | HTML5, CSS3, JavaScript |
| **Data Handling** | pandas, numpy |

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/konduru-rohith09/socialmediatextmoderization.git
cd socialmediatextmoderization
2ï¸âƒ£ Create a Virtual Environment
python -m venv venv
venv\Scripts\activate3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt


If no requirements.txt file is available, install manually:

pip install fastapi uvicorn torch transformers pandas numpy scikit-learn spacy nltk emoji
python -m spacy download en_core_web_sm

ğŸ§  Model Training
To train or fine-tune the model, open and run the notebook:
jupyter notebook text.ipynb


This notebook will:
âœ… Preprocess the dataset
âœ… Train a BERT-based classifier
âœ… Save the model and tokenizer to Backend/toxic_bert_model/

â–¶ï¸ Running the Application
ğŸ”¹ Backend (FastAPI Server)
cd Backend
uvicorn main:app --reload


Once started, the server will be available at:

http://127.0.0.1:8000

ğŸ”¹ Frontend

Open your browser and visit the above URL to access the interactive text moderation interface.

ğŸ§° Troubleshooting
Issue	Solution
Model directory not found	Ensure Backend/toxic_bert_model/ contains model files like pytorch_model.bin
TemplateNotFound: index.html	Place index.html inside the frontend/ folder
nltk data missing	Run:
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

ğŸŒŸ Future Enhancements

ğŸ§© Multilingual text moderation support
ğŸ“Š Real-time dashboard for toxicity analytics
ğŸš€ Deploy using Docker, Streamlit, or Hugging Face Spaces

ğŸ¤ Contributing
Contributions are welcome!
To contribute:
Fork this repository

Create a new feature branch (git checkout -b feature-name)
Commit your changes

Push to the branch (git push origin feature-name)
Open a Pull Request

ğŸ“œ License
This project is licensed under the MIT License.
See the LICENSE
 file for details.

ğŸ‘¨â€ğŸ’» Author
Konduru Rohith
ğŸ“ GitHub: @konduru-rohith09

ğŸ’¬ Acknowledgements
Hugging Face Transformers
FastAPI Documentation
spaCy NLP Toolkit
nltk Python Library




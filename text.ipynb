{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7af0141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "729e48ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = \"C:/Users/Rohith Kumar/OneDrive/Desktop/Text_moderization_project\"\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6fa31e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocessing import load_csv_folder, full_preprocessing\n",
    "from models.text_model import train_bert_model, predict_texts\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34b6aaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"C:/Users/Rohith Kumar/OneDrive/Desktop/Text_moderization_project/data/text\"\n",
    "df = load_csv_folder(folder_path)\n",
    "df = full_preprocessing(df, text_column=\"comment_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86e4537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"C:/Users/Rohith Kumar/OneDrive/Desktop/Text_moderization_project/data/text\"\n",
    "df = load_csv_folder(folder_path)\n",
    "df = full_preprocessing(df, text_column=\"comment_text\")\n",
    "\n",
    "label_cols = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "df = df.dropna(subset=label_cols)\n",
    "df = df[(df[label_cols] != -1).all(axis=1)]\n",
    "\n",
    "x = df['lemmatized_text']\n",
    "y = df[label_cols].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b65d2514",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "df = df.dropna(subset=label_cols)\n",
    "df = df[(df[label_cols] != -1).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a58dad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['lemmatized_text']\n",
    "y = df[label_cols].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f7d57da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f7d3cd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_small = x_train.sample(n=1500, random_state=42)\n",
    "y_train_small = y_train.loc[x_train_small.index]\n",
    "\n",
    "x_test_small = x_test.sample(n=600, random_state=42)\n",
    "y_test_small = y_test.loc[x_test_small.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "152970f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users/Rohith Kumar/OneDrive/Desktop/Text_moderization_project\\models\\text_model.py:63: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  )\n",
      "c:\\Users\\Rohith Kumar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [564/564 1:54:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.531000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.262200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.138100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.108300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.062600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.090500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.116700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.124700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.108400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.078500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.086800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.089000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.074800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.034700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.057500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.051900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.063800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.090800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.040800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.028100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.062900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.048300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.097200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.065500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.043300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.059200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.035900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.087800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rohith Kumar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 01:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer, trainer, results = train_bert_model(\n",
    "    x_train_small, y_train_small,\n",
    "    \n",
    "    x_test_small, y_test_small,\n",
    "    epochs=3,\n",
    "    batch_size=8,\n",
    "    threshold=0.3  \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8f61c467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results:\n",
      "eval_loss: 0.0702\n",
      "eval_accuracy: 0.9819\n",
      "eval_precision: 0.7059\n",
      "eval_recall: 0.4186\n",
      "eval_f1: 0.5255\n",
      "eval_runtime: 107.9403\n",
      "eval_samples_per_second: 5.5590\n",
      "eval_steps_per_second: 0.6950\n",
      "epoch: 3.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluation Results:\")\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7a48cf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: tensor([[1, 0, 1, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 0]], dtype=torch.int32)\n",
      "Probabilities: tensor([[0.6980, 0.2084, 0.4653, 0.1295, 0.3637, 0.1270],\n",
      "        [0.0528, 0.0094, 0.0196, 0.0081, 0.0168, 0.0077]])\n"
     ]
    }
   ],
   "source": [
    "sample_texts = [\"You are so stupid!\", \"I love this product!\"]\n",
    "preds, probs = predict_texts(model, tokenizer, sample_texts)\n",
    "print(\"Predictions:\", preds)\n",
    "print(\"Probabilities:\", probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36137977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./Backend/toxic_bert_model\\\\tokenizer_config.json',\n",
       " './Backend/toxic_bert_model\\\\special_tokens_map.json',\n",
       " './Backend/toxic_bert_model\\\\vocab.txt',\n",
       " './Backend/toxic_bert_model\\\\added_tokens.json',\n",
       " './Backend/toxic_bert_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "save_dir = \"./Backend/toxic_bert_model\"  # path inside your project\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model.save_pretrained(save_dir)\n",
    "\n",
    "# Save tokenizer\n",
    "tokenizer.save_pretrained(save_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
